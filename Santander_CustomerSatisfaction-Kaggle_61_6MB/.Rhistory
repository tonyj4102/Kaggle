install.packages(c('rzmq','repr','IRkernel','IRdisplay'),
repos = c('http://irkernel.github.io/', getOption('repos')))
IRkernel::installspec()
?IRkernel
??IRkernel
IRkernel::installspec()
update.packages(repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c("rzmq", "repr", "IRkernel", "IRdisplay"))
IRKernel.libPaths()
path.package(IRKernel)
path.package("IRKernel)
path.package("IRKernel")
install.packages("IRKernel")
library(IRKernel)
install.packages("IRkernel")
library(IRkernel)
install.packages('ff')
install.packages("VIM")
install.packages('gridExtra')
install.packages("corrplot")
install.packages("Borutu")
library(Borutu)
install.packages("Boruta")
install.packages("mlbench")
install.packages("Hmisc")
setwd("~/Dropbox/2b-Projects/Santander_CustomerSatisfaction-Kaggle")
#read in data
setwd("~/Dropbox/2b-Projects/Santander_CustomerSatisfaction-Kaggle")
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
#### New feature for 0 count per line
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
##### Removing IDs
train$ID <- NULL
test.id <- Stest$ID
test$ID <- NULL
##### Removing constant features
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
##### Removing identical features
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
str(train$TARGET)
# take only 0.13
set.seed(113)  #15071
spl = sample(nrow(train), 0.10*nrow(train))
Subtrain = train[spl,]
# prepare data
y=Subtrain$TARGET
y=factor(y)
str(y)
Subtrain$TARGET<-NULL
library(caret)
library(mlbench)
library(Hmisc)
library(randomForest)
start.time <- Sys.time()
subsets <- c(1:5, 10, 50, 100, 300)
rfRFE <-  list(summary = defaultSummary,
fit = function(x, y, first, last, ...){
library(randomForest)
randomForest(x, y, do.trace=TRUE, importance = first, ...)
},
pred = function(object, x)  predict(object, x),
rank = function(object, x, y) {
vimp <- varImp(object)
vimp <- vimp[order(vimp$Overall,decreasing = TRUE),,drop = FALSE]
vimp$var <- rownames(vimp)
vimp
},
selectSize = pickSizeBest,
selectVar = pickVars)
ctrl$functions <- rfRFE
ctrl$returnResamp <- "all"
ctrl <- rfeControl(functions = lmFuncs,
method = "repeatedcv", #10-fold cross-validation
repeats = 5,
verbose = FALSE)
ctrl$functions <- rfRFE
ctrl$returnResamp <- "all"
set.seed(10)
start.time <- Sys.time()
rfProfile <- rfe(Subtrain, y, sizes = subsets, rfeControl = ctrl)
start.time <- Sys.time()
rfProfile <- rfe(Subtrain, y, sizes = subsets, rfeControl = ctrl)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
rfProfile
start.time <- Sys.time()
filterCtrl <- sbfControl(functions = rfSBF,
method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(Subtrain, y, sbfControl = filterCtrl)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
rfWithFilter
str(rfWithFilter)
str(rfWithFilter$optVariables)
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
#### New feature for 0 count per line
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
##### Removing IDs
train$ID <- NULL
test.id <- Stest$ID
test$ID <- NULL
colmkeep<-c(rfWithFilter$optVariables)
train <- train[,colmkeep]
str(train)
##### Removing IDs
train$ID <- NULL
test.id <- Stest$ID
test$ID <- NULL
##### Removing constant features
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
##### Removing identical features
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
y=Subtrain$TARGET
y=factor(y)
str(y)
Subtrain$TARGET<-NULL
# XGBoost and data prep
library(xgboost)
library(Matrix)
#train <- sparse.model.matrix(train.y ~ ., data = train)
dtrain <- xgb.DMatrix(data=train, label=y)
watchlist <- list(train=dtrain)
dtrain <- xgb.DMatrix(data=train, label=as.matrix(y)
dtrain <- xgb.DMatrix(data=train, label=as.matrix(y))
dtrain <- xgb.DMatrix(data=as.matrix(train), label=as.matrix(y))
y=train$TARGET
y=factor(y)
str(y)
train$TARGET<-NULL
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
colmkeep<-c(rfWithFilter$optVariables)
train <- train[,colmkeep]
str(train)
##### Removing IDs
train$ID <- NULL
test.id <- Stest$ID
test$ID <- NULL
##### Removing constant features
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
y=train$TARGET
y=factor(y)
str(y)
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
y=train$TARGET
y=factor(y)
str(y)
train$TARGET<-NULL
colmkeep<-c(rfWithFilter$optVariables)
train <- train[,colmkeep]
str(train)
train$ID <- NULL
test.id <- Stest$ID
test$ID <- NULL
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
dtrain <- xgb.DMatrix(data=as.matrix(train), label=as.matrix(y))
watchlist <- list(train=dtrain)
param <- list(  objective           = "binary:logistic",
booster             = "gbtree",
eval_metric         = "auc",
eta                 = 0.0202048,
max_depth           = 5,
subsample           = 0.6815,
colsample_bytree    = 0.701
)
feature.names <- setdiff(names(train), toRemove)
train <- train[, feature.names]
test <- test[, feature.names]
library(xgboost)
library(Matrix)
#train <- sparse.model.matrix(train.y ~ ., data = train)
dtrain <- xgb.DMatrix(data=as.matrix(train), label=as.matrix(y))
watchlist <- list(train=dtrain)
param <- list(  objective           = "binary:logistic",
booster             = "gbtree",
eval_metric         = "auc",
eta                 = 0.0202048,
max_depth           = 5,
subsample           = 0.6815,
colsample_bytree    = 0.701
)
clf <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 560,
verbose             = 1,
watchlist           = watchlist,
maximize            = FALSE
)
pred <-predict(clf,as.matrix(test))
submission52 <- data.frame(ID=test.id, TARGET=pred)
cat("saving the submission file\n")
write.csv(submission52, "submission#52.csv", row.names = F)
test.id <- Stest$ID
test.id <- test$ID
submission52 <- data.frame(ID=test.id, TARGET=pred)
cat("saving the submission file\n")
write.csv(submission52, "submission#52.csv", row.names = F)
submission52 <- data.frame(ID=test.id, TARGET=pred)
test=read.csv("santander_test.csv")
test.id <- test$ID
pred <-predict(clf,as.matrix(test))
submission52 <- data.frame(ID=test.id, TARGET=pred)
cat("saving the submission file\n")
write.csv(submission52, "submission#52.csv", row.names = F)
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
y=train$TARGET
y=factor(y)
str(y)
train$TARGET<-NULL
train$ID <- NULL
test.id <- test$ID
test$ID <- NULL
colmkeep<-c(rfWithFilter$optVariables)
train <- train[,colmkeep]
str(train)
dtrain <- xgb.DMatrix(data=as.matrix(train), label=as.matrix(y))
watchlist <- list(train=dtrain)
param <- list(  objective           = "binary:logistic",
booster             = "gbtree",
eval_metric         = "auc",
eta                 = 0.0202048,
max_depth           = 5,
subsample           = 0.6815,
colsample_bytree    = 0.701
)
clf <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 560,
verbose             = 1,
watchlist           = watchlist,
maximize            = FALSE
)
pred <-predict(clf,as.matrix(test))
submission53 <- data.frame(ID=test.id, TARGET=pred)
cat("saving the submission file\n")
write.csv(submission53, "submission#53.csv", row.names = F)
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
y=train$TARGET
y=factor(y)
str(y)
train$TARGET<-NULL
train$ID <- NULL
test.id <- test$ID
test$ID <- NULL
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
train$var38 <- log(train$var38)
test$var38 <- log(test$var38)
train$var38 <- log(train$var38)
test$var38 <- log(test$var38)
train$saldo_medio_var5_hace3<-log(abs(train$saldo_medio_var5_hace3))
test$saldo_medio_var5_hace3<-log(abs(test$saldo_medio_var5_hace3))
feature.names <- setdiff(names(train), toRemove)
train <- train[, feature.names]
test <- test[, feature.names]
dtrain <- xgb.DMatrix(data=as.matrix(train), label=as.matrix(y))
watchlist <- list(train=dtrain)
param <- list(  objective           = "binary:logistic",
booster             = "gbtree",
eval_metric         = "auc",
eta                 = 0.0202048,
max_depth           = 5,
subsample           = 0.6815,
colsample_bytree    = 0.701
)
clf <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 560,
verbose             = 1,
watchlist           = watchlist,
maximize            = FALSE
)
pred <-predict(clf,as.matrix(test))
submission54 <- data.frame(ID=test.id, TARGET=pred)
cat("saving the submission file\n")
write.csv(submission54, "submission#54.csv", row.names = F)
train=read.csv("train.csv")
test=read.csv("santander_test.csv")
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
y=train$TARGET
y=factor(y)
str(y)
train$TARGET<-NULL
train$ID <- NULL
test.id <- test$ID
test$ID <- NULL
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
feature.names <- setdiff(names(train), toRemove)
train <- train[, feature.names]
test <- test[, feature.names]
library("devtools")
library(SuperLearner)
str(y)
SL.library <- c("SL.knn",
"SL.randomForest",
"SL.nnet"
#"SL.ridge",
#"SL.glmnet",
#"SL.gbm"
)
method <- "method.NNLS"
family <- "binomial"
fitSL2 <- SuperLearner(y, train,newX = test,
family = family,
SL.library = SL.library,
method = method)
is.vector(y)
unlist(y)
is.vector(y)
y<-c(y)
is.vector(y)
fitSL2 <- SuperLearner(y, train,newX = test,
family = family,
SL.library = SL.library,
method = method)
